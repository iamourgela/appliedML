{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees and Random Forests \n",
    "\n",
    "\n",
    "Decision Tree is a widely-used supervised learning algorithm which is suitable for both classification and regression tasks. Decision Trees serve as building blocks for some prominent ensemble learning algorithms such as Random Forests and XGBoost. A decision tree builds upon iteratively asking questions to partition data. \n",
    "\n",
    "<img src=\"./decisiontree_and_randomforest.png\"  width=50% />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries \n",
    "\n",
    "Before we import the data, let's load the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree # for decision tree models\n",
    "from sklearn.ensemble import RandomForestClassifier # for Random Forest (ensemble) method\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "In this notebook, we will look into the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)). <br/>(Note: the dataset is provided in your Lab folder). \n",
    "\n",
    "1. The dataset is about the patients who were detected with 2 kinds of breast cancer : Malignant or Benign\n",
    "2. The features given here are the characteristics of the cell nuclei computed from the fine needle aspirate (FNA) of a breast mass.\n",
    "3. Ten real-valued features are computed for each cell nucleus as follows:\n",
    "    - radius (mean of distances from center to points on the perimeter)\n",
    "    - texture (standard deviation of gray-scale values)\n",
    "    - perimeter\n",
    "    - area\n",
    "    - smoothness (local variation in radius lengths)\n",
    "    - compactness (perimeter^2 / area - 1.0)\n",
    "    - concavity (severity of concave portions of the contour)\n",
    "    - concave points (number of concave portions of the contour)\n",
    "    - symmetry\n",
    "    - fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "#### Importing the data \n",
    "\n",
    "As with the previous Labs, we will start by loading the provided dataset \"breast_cancer.csv\" into a `DataFrame` named **\"input_data\"** using once more the function  `pd.read_csv()` (Check the pandas [read_csv() documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) if needed). \n",
    "- To get acquainted with our data, let’s look at the first 5 entries using `head()`\n",
    "- Check and print the dimensionality of the data using `shape`\n",
    "- The dataset is provided in your Lab folder (no need to download it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the breast_cancer.csv file into a variable named \"input_data\" \n",
    "# Print the dimensionality of the input_data DataFrame\n",
    "# Show the first 5 rows of input_data\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the info for your data\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Question: can you spot which is the target variable we are trying to predict? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Quite often in our analyses, we are provided with columns such identifiers (IDs), which do not contribute any or much information towards the overall analysis. We should therefore learn how to handle them. We can either set them as an index (should we think this may be of use at some point later on) or drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column 'id' contains an Identification number and does not contribute to the analysis\n",
    "# We can EITHER (1) use the function set_index() to set the 'id' as a row index \n",
    "# OR use (2) drop() to remove the 'id' column (remember to set the axis argument). \n",
    "# In both cases, you could use inplace=True. If inplace=True, no assignment needs to happen. \n",
    "# Alternatively, if we do not use inplace=True, we need to assign back to \"input_data\". \n",
    "# Check the results once more using head() to ensure your changes have gone through \n",
    "\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Split the data into input variable X and class vector y\n",
    "\n",
    "Decision Trees and Random Forests follow a similar workflow to other supervised models in `sklearn`. We need to first start by setting the `X` matrix (input feature matrix) and `y` vector (class target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common step across all Supervised Machine Learning models in Python\n",
    "\n",
    "# Assign the feature data into a new variable named \"X\"  \n",
    "# Extract all columns **except** from the label column \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Assign the target data (label/class column) into a new variable named \"y\"\n",
    "# Extract only the label (class) column\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: print the dimensions (shape) for both X and y \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the class frequencies\n",
    "\n",
    "An important aspect to understand before applying any classification algorithm is how the output labels are distributed. Are they evenly distributed or not? Imbalances in distribution of labels can often lead to poor classification results for the minority class even if the classification results for the majority class are very good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function value_counts() on the y variable in order to check the distribution of the binary class \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in the frequencies of each class in a seaborn countplot using the input_data DataFrame\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping (encoding) the categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the class variable to be in machine-readable form and ready to be used by ML models, it needs to be encoded in a numerical format. `LabelEncoder` from `sklearn` can be used to encode target labels with value between `0` and `n_classes-1`. \n",
    "\n",
    "**This transformer should be used to encode target values, i.e. y, and not the input X** (in which case, we can use One Hot Encoding or other ways of encoding). Read more about [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) and [Transforming the prediction variable(y)](https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical values into numbers using the LabelEncoder from sklearn\n",
    "\n",
    "# Instantiate a LabelEncoder() object and save it to a new variable \"le\"\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "\n",
    "# Fit the label encoder \"le\" using fit_transform() on y (pass it as a parameter) \n",
    "# Assign back to \"y\". The fit_transform() function takes a categorical column \n",
    "# and converts/maps it to numerical values.\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check once more the distribution of the binary class. \n",
    "# Hint: You may need to convert your y into a pd.DataFrame.  \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning - Classification\n",
    "\n",
    "For every classification model built with scikit-learn, we will follow four main steps:\n",
    "\n",
    "1. Building the classification model (using either default, pre-defined or optimized parameters)\n",
    "2. Training (*fitting*) the model\n",
    "3. Testing (*predicting*) the model\n",
    "4. Performance evaluation using various metrics.\n",
    "\n",
    "### Train-Test Split\n",
    "\n",
    "Training and testing a classification model on the same dataset is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data (poor generalisation). To use different datasets for training and testing, we need to split our dataset into two disjoint sets: train and test (Holdout method).\n",
    "\n",
    "Use `sklearn`’s `train_test_split()` function to randomly split the data into train and test sets (visit the [train_test_split documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and the  [model cross-validation documentation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the train_test_split() function from sklearn and pass the following arguments: \n",
    "# (1) the X matrix (2) the y vector (3) test_size=0.30 \n",
    "# (4) stratify=y (5) random_state=0 (for reproducibility)\n",
    "# Assign the results into the new variables X_train, X_test, y_train, y_test (simultaneously)\n",
    "# Note: when working with imbalances, it is important to stratify y when doing a train_test_split()\n",
    "\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "\n",
    "# Print the dimensionality (shape) of X_train, X_test, y_train, y_test \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: it’s good practice to split the train and test sets before doing any feature engineering and/or scaling to avoid data leakage.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling \n",
    "\n",
    "Decision Trees and Random Forests need little to no data pre-processing so we can skip the step of Scaling / Normalization for today's Lab, mainly to highlight the feature splits in the following `plot_tree` visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Decision Tree Classifier \n",
    "\n",
    "Decision Tree classifiers construct classification models in the form of a tree structure. A decision tree progressively splits the training set into smaller subsets. Each node of the tree represents a subset of the data. Once a new sample is presented to the data, it is classified according to the test condition generated for each node of the tree.\n",
    "\n",
    "<!-- #### Decision Tree Classifier parameters\n",
    "- `criterion`: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "- `splitter`: The strategy used to choose the split at each node. Supported strategies are \"best\" to choose the best split and \"random\" to choose the best random split.\n",
    "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "- `min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "- `max_features`: The number of features to consider when looking for the best split.\n",
    "- `max_leaf_nodes`: Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "- `min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf. -->\n",
    "\n",
    "#### Decision Tree Classifier with pre-defined parameters\n",
    "\n",
    "Let’s start with a decision tree classifier using `max_depth=3`. Do not forget to also set `random_state=0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Instantiate the DecisionTreeClassifier() classifier using the pre-defined parameter \"max_depth=3\"\n",
    "# Also use \"random_state=0\" for reproducibility. Assign the result into a new variable named \"dt\"\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Step 2 - Fit the DT model to the training set (use dt.fit())\n",
    "# Pass as arguments X_train and y_train \n",
    "# No need to assign it into a new variable when calling fit()\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Step 3 - Predict the test data using the dt model (use dt.predict())\n",
    "# Pass as argument only X_test (not y_test!)\n",
    "# Save the prediction output into a new variable \"y_pred\"\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Step 4 - Print the final overall accuracy for the test set using metrics.accuracy_score()\n",
    "# Pass as parameters the actual values from y_test and the predicted values from y_pred\n",
    "\n",
    "print('Test set accuracy: ', ###### FILL IN YOUR SOLUTION HERE ###### )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion_matrix for the test set using metrics.confusion_matrix()\n",
    "# Pass as parameters the actual values from y_test and the predicted values from y_pred\n",
    "\n",
    "print(###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification_report for the test set using metrics.classification_report()\n",
    "# Pass as parameters the actual values from y_test and the predicted values from y_pred\n",
    "\n",
    "print(###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of a tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our model using `plot_tree()` function ([`sklearn.tree.plot_tree()` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,14))\n",
    "plot_tree(dt, feature_names=X_train.columns, filled=True, fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model keeps splitting the nodes until all the nodes are pure (i.e. contain samples from only one class) or when a threshold such as `max_depth` is reached. \n",
    "\n",
    "- In each box, the first line indicates the name of the feature (i.e. column). If we do not name the columns using `feature_names`, the index of the column is shown. Samples indicates the number of observations (i.e. rows) and the value shows the distribution of these samples according to the target variable. \n",
    "\n",
    "- Gini is a measure of impurity. The other function to evaluate the quality of a split is entropy which is a measure of uncertainty or randomness. The more randomness a variable has, the higher the entropy is. We can select gini or impurity using the `criterion` parameter. The default value is gini.\n",
    "\n",
    "- When the algorithm performs a split, the main goal is to decrease impurity as much as possible. The more the impurity decreases, the more informative power that split gains. As the tree gets deeper, the amount of impurity decrease becomes lower. We can use this to prevent the tree from doing further splits. The hyperparameter for this task is `min_impurity_decrease`. It is set to zero by default.\n",
    "\n",
    "- Another hyperparameter to control the depth of a tree is `max_depth`. It does not make any calculations regarding impurity or sample ratio. The model stops splitting when `max_depth` is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "Random Forest is one of the most popular and most powerful machine learning algorithms. Random forest is a supervised learning algorithm that is used for classification and regression tasks. The \"forest\" is an **ensemble of decision trees** (each of which is based on a random subset of the data). The general idea of the bagging method is that a combination of learning models reduces the chance of overfitting. \n",
    "\n",
    "#### Random Forest Classifier with pre-defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Instantiate the RandomForestClassifier() classifier using some pre-defined parameters\n",
    "# Set the number of trees to 100 in the RF using 'n_estimators=100'. Also set 'random_state=0' for reproducibility. \n",
    "# Assign the result into a new variable named \"rf\"\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Step 2 - Fit the rf model to the training set (use rf.fit())\n",
    "# Pass as arguments the train matrix X_train and the class vec y_train \n",
    "# No need to assign it into a new variable when calling fit()\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Step 3 - Predict the test data using the rf model (use rf.predict())\n",
    "# Pass as argument only the test matrix X_test\n",
    "# Save the prediction output into a new variable \"y_pred\"\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Step 4 - Print the final overall accuracy for the test set using metrics.accuracy_score()\n",
    "# Pass as parameters the actual values from y_test and the predicted values from y_pred\n",
    "\n",
    "print('Test set accuracy: ', ###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification_report for the test set using metrics.classification_report()\n",
    "# Pass as parameters the actual values from y_test and the predicted values from y_pred\n",
    "\n",
    "print(###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF hyperparameter tuning\n",
    "\n",
    "#### GridSearchCV and RandomizedSearchCV\n",
    "\n",
    "All classification models have a set of parameters that need to be optimised (tuned). \n",
    "- Grid search is a process that searches exhaustively through a manually specified subset of the hyperparameter space. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) implements the most obvious way of finding an optimal value for anything — it simply tries all the possible values (that you pass) one at a time and returns which one yielded the best model results, based on the scoring that you want, such as accuracy on the validation set. \n",
    "- In contrast to GridSearchCV, with [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) method, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by `n_iter`.\n",
    "\n",
    "#### RF hyperparameter options\n",
    "\n",
    "Random forests offer *several* hyperparameters that can be tuned. The optimal choice for these parameters is highly *data-dependent*. Rather than trying one-by-one predefined values for each hyperparameter, we can automate this process using once more `GridSearchCV()` or `RandomizedSearchCV()`. The following represent some of the hyperparameters that can be tuned for random forest classifiers:\n",
    "\n",
    "- `n_estimators`: The number of decision trees in the random forest.\n",
    "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than `min_samples_split` samples.\n",
    "- `max_features`: The maximum number of features to consider when looking for the best split. \n",
    "- `criterion`: The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Gini impurity is defined as the sum of the squared probabilities of each class, while information gain is defined as the decrease in entropy. In the case of Random Forest, a decrease in entropy can be understood as the increase in the purity of the node. In other words, the Random Forest tries to maximize the information gain at each node.\n",
    "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "- `min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when `sample_weight` is not provided.\n",
    "- `max_features`: The number of features to consider when looking for the best split.\n",
    "- `max_leaf_nodes`: Grow a tree with `max_leaf_nodes` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "- `min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
    "- `bootstrap`: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.\n",
    "- `oob_score`: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
    "\n",
    "####  RF hyperparameter tuning \n",
    "\n",
    "As a first step, create a dictionary of hyperparameter ranges and conduct a grid or random search with cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try RandomizedSearchCV() or GridSearchCV() (significantly slower) with \n",
    "# 5-fold or 10-fold cross-validation (cv=5 or cv=10)\n",
    "# (more cv folds reduces the chances of overfitting but also increases the run time) \n",
    "# using a dictionary of parameters such as the ones defined as follows  \n",
    "\n",
    "# Create the dictionary of hyperparameters \n",
    "param_grid = {'n_estimators': np.arange(10, 200, 10),\n",
    "              'max_depth': [np.arange(1, 50, 2), None],\n",
    "              'max_features' : ['sqrt', 'log2', None], \n",
    "              'min_samples_split': [1, 3, 5, 10], \n",
    "              'min_samples_leaf': [1, 3, 10],\n",
    "              'criterion': ['gini', 'entropy'], \n",
    "             }\n",
    "\n",
    "# Set up the RandomizedSearchCV and assign to a new variable named cv_rf\n",
    "# The most important arguments in RandomizedSearchCV are n_iter, \n",
    "# which controls the number of different combinations to try, \n",
    "# and cv which is the number of folds to use for cross validation \n",
    "# Let's use 30 iterations and 10 folds respectively. \n",
    "# Set n_jobs = -1 to run in parallel. -1 means using all processors. \n",
    "\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "\n",
    "# Fit the grid or random search model to X_train and y_train \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Report the optimal parameters using 'cv_rf.best_params_'\n",
    "print('Best Parameters: \\n', ###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best model (with the optimal parameters) using 'cv_rf.best_estimator_'\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the final optimized model using the best parameters as detected from the exhaustive grid search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the classifier using the optimal parameters detected by the tuning process\n",
    "\n",
    "# Save the result cv_rf.best_estimator_ into a new variable rf_opt \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Fit the optimal model rf_opt to the training set. Pass as arguments X_train and y_train\n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "# Predict the test data X_test. Use rf_opt.predict(). \n",
    "# Assign the result into a new variable y_pred \n",
    "\n",
    "###### FILL IN YOUR SOLUTION HERE ######\n",
    "\n",
    "\n",
    "# Report the final overall accuracy using metrics.accuracy_score(). \n",
    "# Pass as parameters y_test and y_pred for the test accuracy \n",
    "\n",
    "print('Test set accuracy: ', ###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance our model with metrics.classification report() \n",
    "# Pass as parameters y_test and y_pred \n",
    "print(###### FILL IN YOUR SOLUTION HERE ######)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature importance is a key concept in machine learning that refers to the relative importance of each feature in the training data. In other words, it tells us which features are most predictive of the target variable. Determining feature importance is one of the key steps of machine learning model development pipeline. Feature importance can be calculated in a number of ways, but all methods typically rely on calculating some sort of score that measures how often a feature is used in the model and how much it contributes to the overall predictions.\n",
    "\n",
    "Feature importances are provided by the fitted attribute `feature_importances_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance from the rf classifier using rf_opt.feature_importances_\n",
    "# Cast it into a pd.DataFrame and use sort_values to sort by the importance \n",
    "\n",
    "feature_scores = pd.DataFrame(rf_opt.feature_importances_, index=X_train.columns, columns=['Importance'])\n",
    "feature_scores.sort_values(by='Importance', ascending=False, inplace=True) \n",
    "feature_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rf_opt.feature_importances_ in a barplot \n",
    "\n",
    "f, ax = plt.subplots(figsize=(30, 40))\n",
    "ax = sns.barplot(x='Importance', y=feature_scores.index, data=feature_scores)\n",
    "ax.set_title(\"RF feature importance\", size = 20)\n",
    "ax.set_yticklabels(feature_scores.index, size = 20)\n",
    "ax.set_xlabel(\"Feature importance score\", size = 20)\n",
    "ax.set_ylabel(\"Features\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Plotting the boundaries of the optimal Random Forest Classifier \n",
    "\n",
    "Based on http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    " \n",
    "def plot_rf_boundaries(feature_a, feature_b):\n",
    "    X_combined = np.vstack((X_train, X_test))[:,(feature_a,feature_b)]\n",
    "    y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "    # Refitting the classifier with 2D data \n",
    "    rf_opt.fit(X_combined, y_combined)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    plot_decision_regions(X_combined, y_combined, clf=rf_opt)\n",
    "    plt.xlabel(X_train.columns[feature_a])\n",
    "    plt.ylabel(X_train.columns[feature_b])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('RF on Breast Cancer Wisconsin (Diagnostic) Data Set.')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Plot feature 1 vs 2 (or try a combination of different feature numbers)\n",
    "plot_rf_boundaries(1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
