{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de638d5e",
   "metadata": {},
   "source": [
    "# House Price Prediction - Regression Analysis\n",
    "This notebook includes EDA, preprocessing, feature selection, model training, and tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2287c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr[['SalePrice']].sort_values(by='SalePrice', ascending=False), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation with SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='OverallQual', y='SalePrice', data=train_df)\n",
    "plt.title('SalePrice by OverallQual')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=train_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('SalePrice by Neighborhood')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop high-missing columns\n",
    "missing = train_df.isnull().sum()\n",
    "drop_cols = missing[missing > 0.4 * len(train_df)].index.tolist()\n",
    "\n",
    "train_df.drop(columns=drop_cols, inplace=True)\n",
    "test_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Impute remaining\n",
    "cat_cols = train_df.select_dtypes(include='object').columns\n",
    "num_cols = train_df.select_dtypes(include=['int64', 'float64']).drop(columns=['SalePrice', 'Id']).columns\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "train_df[num_cols] = num_imputer.fit_transform(train_df[num_cols])\n",
    "train_df[cat_cols] = cat_imputer.fit_transform(train_df[cat_cols])\n",
    "test_df[num_cols] = num_imputer.transform(test_df[num_cols])\n",
    "test_df[cat_cols] = cat_imputer.transform(test_df[cat_cols])\n",
    "\n",
    "# One-hot encoding\n",
    "train_encoded = pd.get_dummies(train_df, drop_first=True)\n",
    "test_encoded = pd.get_dummies(test_df, drop_first=True)\n",
    "\n",
    "X = train_encoded.drop(columns=['SalePrice', 'Id'])\n",
    "y = train_encoded['SalePrice']\n",
    "X_test = test_encoded.reindex(columns=X.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f68170",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded['SalePriceBin'] = pd.qcut(train_encoded['SalePrice'], q=10, labels=False)\n",
    "parts = []\n",
    "for label in train_encoded['SalePriceBin'].unique():\n",
    "    subset = train_encoded[train_encoded['SalePriceBin'] == label]\n",
    "    sampled = resample(subset, replace=True, n_samples=150, random_state=1)\n",
    "    parts.append(sampled)\n",
    "\n",
    "train_bal = pd.concat(parts)\n",
    "X_bal = train_bal.drop(columns=['SalePrice', 'Id', 'SalePriceBin'])\n",
    "y_bal = train_bal['SalePrice']\n",
    "X_bal_scaled = scaler.fit_transform(X_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aace579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "param_rf = {'n_estimators': [50, 100], 'max_depth': [5, 10]}\n",
    "grid_rf = GridSearchCV(RandomForestRegressor(random_state=0), param_rf, scoring='neg_root_mean_squared_error', cv=3)\n",
    "grid_rf.fit(X_bal_scaled, y_bal)\n",
    "\n",
    "# Gradient Boosting\n",
    "param_gb = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1], 'max_depth': [3, 5]}\n",
    "grid_gb = GridSearchCV(GradientBoostingRegressor(random_state=0), param_gb, scoring='neg_root_mean_squared_error', cv=3)\n",
    "grid_gb.fit(X_bal_scaled, y_bal)\n",
    "\n",
    "print(\"Best RF:\", grid_rf.best_params_)\n",
    "print(\"Best GB:\", grid_gb.best_params_)\n",
    "print(\"RF CV RMSE:\", -grid_rf.best_score_)\n",
    "print(\"GB CV RMSE:\", -grid_gb.best_score_)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
